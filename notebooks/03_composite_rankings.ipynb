{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CFP Composite Rankings\n",
        "\n",
        "This notebook combines resume and predictive rankings with strength metrics to generate final composite rankings.\n",
        "\n",
        "## Ranking Components\n",
        "\n",
        "- **Resume (50%)**: What teams have accomplished (Colley + Win%)\n",
        "- **Predictive (30%)**: Team strength/ability (Massey + Elo)\n",
        "- **SOR (10%)**: Strength of Record (schedule-adjusted wins)\n",
        "- **SOS (10%)**: Strength of Schedule (opponent quality)\n",
        "\n",
        "## Conference Adjustment\n",
        "\n",
        "Power 5 teams receive a 3% boost, Group of 5 teams receive a 3% penalty to account for historical CFP committee preferences.\n",
        "\n",
        "## Tie-Breaker Protocol\n",
        "\n",
        "1. Head-to-head result\n",
        "2. Common opponents record\n",
        "3. SOS rank\n",
        "4. SOR rank\n",
        "5. Composite score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from notebook_utils import (\n",
        "    setup_notebook_env,\n",
        "    load_cached_games,\n",
        "    create_output_dirs,\n",
        "    print_ranking_summary,\n",
        "    validate_config\n",
        ")\n",
        "\n",
        "setup_notebook_env()\n",
        "\n",
        "from src.utils.metrics import calculate_sor, calculate_sos\n",
        "from src.utils.conference import apply_conference_adjustment, get_conference_tier\n",
        "from src.playoff.bracket import apply_tiebreaker\n",
        "\n",
        "# Configuration\n",
        "year = 2025\n",
        "week = 15\n",
        "\n",
        "# Validate configuration\n",
        "is_valid, error_msg = validate_config(year, week)\n",
        "if not is_valid:\n",
        "    raise ValueError(error_msg)\n",
        "\n",
        "# Create output directories\n",
        "output_dirs = create_output_dirs()\n",
        "rankings_dir = output_dirs['rankings']\n",
        "viz_dir = output_dirs['visualizations']\n",
        "\n",
        "print(f'\\nâœ… Configuration: {year} Season, Week {week}')\n",
        "print(f'âœ… Output directory: {rankings_dir}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Component Rankings and Games Data\n",
        "\n",
        "# Load individual ranking components\n",
        "predictive_rankings = pd.read_csv(rankings_dir / f'predictive_rankings_{year}_week{week}.csv')\n",
        "colley_rankings = pd.read_csv(rankings_dir / f'colley_rankings_{year}_week{week}.csv')\n",
        "win_pct_rankings = pd.read_csv(rankings_dir / f'win_pct_rankings_{year}_week{week}.csv')\n",
        "\n",
        "# Load games data\n",
        "games_df = load_cached_games(year, week)\n",
        "\n",
        "print(f'âœ… Loaded {len(colley_rankings)} teams from component rankings')\n",
        "print(f'âœ… Loaded {len(games_df)} games')\n",
        "print(f'\\nComponent Rankings Available:')\n",
        "print(f'  - Colley Matrix (resume)')\n",
        "print(f'  - Win Percentage (resume)')\n",
        "print(f'  - Massey + Elo (predictive)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate SOR (Strength of Record)\n",
        "\n",
        "def calculate_team_sor(team, games_df, power_ratings_dict, baseline_rating=0.75, rating_scale=0.25):\n",
        "    \"\"\"Calculate SOR: Probability average Top-25 team matches this record against this schedule.\"\"\"\n",
        "    team_games = games_df[(games_df['home_team'] == team) | (games_df['away_team'] == team)]\n",
        "    \n",
        "    wins = 0\n",
        "    losses = 0\n",
        "    opponent_ratings = []\n",
        "    \n",
        "    for _, game in team_games.iterrows():\n",
        "        if game['home_team'] == team:\n",
        "            opponent = game['away_team']\n",
        "            won = game['home_score'] > game['away_score']\n",
        "        else:\n",
        "            opponent = game['home_team']\n",
        "            won = game['away_score'] > game['home_score']\n",
        "        \n",
        "        if won:\n",
        "            wins += 1\n",
        "        else:\n",
        "            losses += 1\n",
        "        \n",
        "        opp_rating = power_ratings_dict.get(opponent, 0.5)\n",
        "        opponent_ratings.append(opp_rating)\n",
        "    \n",
        "    team_record = {'wins': wins, 'losses': losses}\n",
        "    \n",
        "    return calculate_sor(\n",
        "        team_record=team_record,\n",
        "        opponent_ratings=opponent_ratings,\n",
        "        baseline_rating=baseline_rating,\n",
        "        rating_scale=rating_scale\n",
        "    )\n",
        "\n",
        "# Normalize predictive scores for opponent ratings\n",
        "scaler = MinMaxScaler()\n",
        "predictive_rankings['normalized_predictive'] = scaler.fit_transform(\n",
        "    predictive_rankings[['predictive_score']]\n",
        ")\n",
        "power_ratings_dict = dict(zip(\n",
        "    predictive_rankings['team'],\n",
        "    predictive_rankings['normalized_predictive']\n",
        "))\n",
        "\n",
        "# Calculate SOR for all teams\n",
        "sor_scores = {}\n",
        "for team in colley_rankings['team']:\n",
        "    sor_scores[team] = calculate_team_sor(team, games_df, power_ratings_dict)\n",
        "\n",
        "print(f'âœ… Calculated SOR for {len(sor_scores)} teams')\n",
        "print(f'\\nTop 5 SOR Scores (higher = harder schedule achievement):')\n",
        "top_sor = sorted(sor_scores.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "for team, score in top_sor:\n",
        "    print(f'  {team}: {score:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate SOS (Strength of Schedule)\n",
        "\n",
        "def calculate_team_sos(team, games_df, include_oor=True, oor_weight=0.33):\n",
        "    \"\"\"Calculate SOS with opponent's opponents to prevent schedule inflation.\"\"\"\n",
        "    team_games = games_df[(games_df['home_team'] == team) | (games_df['away_team'] == team)]\n",
        "    \n",
        "    opponents = []\n",
        "    for _, game in team_games.iterrows():\n",
        "        opponent = game['away_team'] if game['home_team'] == team else game['home_team']\n",
        "        opponents.append(opponent)\n",
        "    \n",
        "    opponents_records = []\n",
        "    opponents_opp_records = []\n",
        "    \n",
        "    for opp in opponents:\n",
        "        opp_games = games_df[(games_df['home_team'] == opp) | (games_df['away_team'] == opp)]\n",
        "        \n",
        "        opp_wins = 0\n",
        "        opp_losses = 0\n",
        "        \n",
        "        # Get opponent's record excluding game against this team\n",
        "        for _, g in opp_games.iterrows():\n",
        "            if (g['home_team'] == team and g['away_team'] == opp) or \\\n",
        "               (g['home_team'] == opp and g['away_team'] == team):\n",
        "                continue\n",
        "            \n",
        "            if g['home_team'] == opp:\n",
        "                if g['home_score'] > g['away_score']:\n",
        "                    opp_wins += 1\n",
        "                else:\n",
        "                    opp_losses += 1\n",
        "            else:\n",
        "                if g['away_score'] > g['home_score']:\n",
        "                    opp_wins += 1\n",
        "                else:\n",
        "                    opp_losses += 1\n",
        "        \n",
        "        opponents_records.append((opp_wins, opp_losses))\n",
        "        \n",
        "        # Get opponent's opponents' records\n",
        "        opp_opp_records = []\n",
        "        for _, g in opp_games.iterrows():\n",
        "            opp_opp = g['away_team'] if g['home_team'] == opp else g['home_team']\n",
        "            \n",
        "            if opp_opp == team:\n",
        "                continue\n",
        "            \n",
        "            opp_opp_games = games_df[\n",
        "                (games_df['home_team'] == opp_opp) | (games_df['away_team'] == opp_opp)\n",
        "            ]\n",
        "            \n",
        "            opp_opp_wins = 0\n",
        "            opp_opp_losses = 0\n",
        "            \n",
        "            for _, gg in opp_opp_games.iterrows():\n",
        "                if gg['home_team'] == opp_opp:\n",
        "                    if gg['home_score'] > gg['away_score']:\n",
        "                        opp_opp_wins += 1\n",
        "                    else:\n",
        "                        opp_opp_losses += 1\n",
        "                else:\n",
        "                    if gg['away_score'] > gg['home_score']:\n",
        "                        opp_opp_wins += 1\n",
        "                    else:\n",
        "                        opp_opp_losses += 1\n",
        "            \n",
        "            opp_opp_records.append((opp_opp_wins, opp_opp_losses))\n",
        "        \n",
        "        opponents_opp_records.append(opp_opp_records)\n",
        "    \n",
        "    return calculate_sos(\n",
        "        opponents_records=opponents_records,\n",
        "        opponents_opp_records=opponents_opp_records,\n",
        "        include_oor=include_oor,\n",
        "        oor_weight=oor_weight\n",
        "    )\n",
        "\n",
        "# Calculate SOS for all teams\n",
        "sos_scores = {}\n",
        "for team in colley_rankings['team']:\n",
        "    sos_scores[team] = calculate_team_sos(team, games_df, include_oor=True, oor_weight=0.33)\n",
        "\n",
        "print(f'âœ… Calculated SOS for {len(sos_scores)} teams')\n",
        "print(f'\\nTop 5 SOS Scores (higher = tougher schedule):')\n",
        "top_sos = sorted(sos_scores.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "for team, score in top_sos:\n",
        "    print(f'  {team}: {score:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge All Components and Calculate Composite Score\n",
        "\n",
        "# Rebuild resume rankings from components\n",
        "resume_data = colley_rankings.merge(\n",
        "    win_pct_rankings[['team', 'wins', 'losses', 'win_pct']],\n",
        "    on='team'\n",
        ")\n",
        "\n",
        "# Calculate resume score (60% Colley, 40% Win%)\n",
        "scaler_resume = MinMaxScaler()\n",
        "resume_data['colley_norm'] = scaler_resume.fit_transform(resume_data[['colley_rating']])\n",
        "resume_data['win_pct_norm'] = resume_data['win_pct']\n",
        "\n",
        "resume_data['resume_score'] = (\n",
        "    0.60 * resume_data['colley_norm'] +\n",
        "    0.40 * resume_data['win_pct_norm']\n",
        ")\n",
        "\n",
        "# Build composite DataFrame\n",
        "composite_df = resume_data[['team', 'wins', 'losses', 'resume_score']].copy()\n",
        "\n",
        "composite_df = composite_df.merge(\n",
        "    predictive_rankings[['team', 'predictive_score']],\n",
        "    on='team',\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "composite_df['sor'] = composite_df['team'].map(sor_scores)\n",
        "composite_df['sos'] = composite_df['team'].map(sos_scores)\n",
        "\n",
        "# Extract conference information from games\n",
        "team_conferences = {}\n",
        "for _, game in games_df.iterrows():\n",
        "    if pd.notna(game.get('home_conference')):\n",
        "        team_conferences[game['home_team']] = game['home_conference']\n",
        "    if pd.notna(game.get('away_conference')):\n",
        "        team_conferences[game['away_team']] = game['away_conference']\n",
        "\n",
        "composite_df['conference'] = composite_df['team'].map(team_conferences)\n",
        "composite_df['conference'] = composite_df['conference'].fillna('Independent')\n",
        "composite_df['conf_tier'] = composite_df['conference'].apply(get_conference_tier)\n",
        "\n",
        "# Normalize all components to 0-1 scale\n",
        "scaler = MinMaxScaler()\n",
        "composite_df['resume_norm'] = scaler.fit_transform(composite_df[['resume_score']])\n",
        "composite_df['predictive_norm'] = scaler.fit_transform(composite_df[['predictive_score']])\n",
        "composite_df['sor_norm'] = scaler.fit_transform(composite_df[['sor']])\n",
        "composite_df['sos_norm'] = scaler.fit_transform(composite_df[['sos']])\n",
        "\n",
        "# UPDATED WEIGHTS: More emphasis on resume to match CFP priorities\n",
        "weights = {\n",
        "    'resume': 0.50,      # Increased from 0.30\n",
        "    'predictive': 0.30,  # Decreased from 0.40\n",
        "    'sor': 0.10,         # Decreased from 0.15\n",
        "    'sos': 0.10          # Decreased from 0.15\n",
        "}\n",
        "\n",
        "# Calculate base composite score\n",
        "composite_df['composite_base'] = (\n",
        "    weights['resume'] * composite_df['resume_norm'] +\n",
        "    weights['predictive'] * composite_df['predictive_norm'] +\n",
        "    weights['sor'] * composite_df['sor_norm'] +\n",
        "    weights['sos'] * composite_df['sos_norm']\n",
        ")\n",
        "\n",
        "# Apply conference adjustments\n",
        "composite_df['composite_score'] = composite_df.apply(\n",
        "    lambda row: apply_conference_adjustment(\n",
        "        team_score=row['composite_base'],\n",
        "        conference=row['conference'],\n",
        "        games_df=games_df,\n",
        "        p5_boost=1.03,   # 3% boost for P5\n",
        "        g5_penalty=0.97  # 3% penalty for G5\n",
        "    ),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Sort and rank\n",
        "composite_df = composite_df.sort_values('composite_score', ascending=False).reset_index(drop=True)\n",
        "composite_df['rank'] = range(1, len(composite_df) + 1)\n",
        "\n",
        "print(f'âœ… Merged all components for {len(composite_df)} teams')\n",
        "print(f'\\nWeighting Configuration:')\n",
        "print(f'  Resume:     {weights[\"resume\"]:.0%} (Colley + Win%)')\n",
        "print(f'  Predictive: {weights[\"predictive\"]:.0%} (Massey + Elo)')\n",
        "print(f'  SOR:        {weights[\"sor\"]:.0%}')\n",
        "print(f'  SOS:        {weights[\"sos\"]:.0%}')\n",
        "print(f'\\nConference Adjustments:')\n",
        "print(f'  Power 5:    +3% boost')\n",
        "print(f'  Group of 5: -3% penalty')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display Top 25 Rankings with Conference Tiers\n",
        "\n",
        "print('=' * 100)\n",
        "print('TOP 25 COMPOSITE RANKINGS'.center(100))\n",
        "print('=' * 100)\n",
        "print()\n",
        "\n",
        "display_df = composite_df[[\n",
        "    'rank', 'team', 'wins', 'losses', 'conference', 'conf_tier',\n",
        "    'resume_score', 'predictive_score', 'sor', 'sos', 'composite_score'\n",
        "]].head(25)\n",
        "\n",
        "print(display_df.to_string(index=False))\n",
        "print()\n",
        "print(f'P5 teams in top 25: {(display_df[\"conf_tier\"] == \"P5\").sum()}')\n",
        "print(f'G5 teams in top 25: {(display_df[\"conf_tier\"] == \"G5\").sum()}')\n",
        "print(f'Independent teams in top 25: {(display_df[\"conf_tier\"] == \"IND\").sum()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add Component Ranks for Analysis\n",
        "\n",
        "composite_df['resume_rank'] = composite_df['resume_score'].rank(method='min', ascending=False).astype(int)\n",
        "composite_df['predictive_rank'] = composite_df['predictive_score'].rank(method='min', ascending=False).astype(int)\n",
        "composite_df['sor_rank'] = composite_df['sor'].rank(method='min', ascending=False).astype(int)\n",
        "composite_df['sos_rank'] = composite_df['sos'].rank(method='min', ascending=False).astype(int)\n",
        "\n",
        "print('Component Rankings Analysis (Top 15):')\n",
        "print()\n",
        "print(composite_df[[\n",
        "    'rank', 'team', 'conf_tier',\n",
        "    'resume_rank', 'predictive_rank', 'sor_rank', 'sos_rank'\n",
        "]].head(15).to_string(index=False))\n",
        "print()\n",
        "print('Legend: Lower rank number = better in that component')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export Final Rankings\n",
        "\n",
        "final_rankings = composite_df[[\n",
        "    'rank', 'team', 'wins', 'losses', 'conference', 'conf_tier',\n",
        "    'resume_score', 'resume_rank',\n",
        "    'predictive_score', 'predictive_rank',\n",
        "    'sor', 'sor_rank',\n",
        "    'sos', 'sos_rank',\n",
        "    'composite_score'\n",
        "]].copy()\n",
        "\n",
        "# Save to rankings directory\n",
        "csv_path = rankings_dir / f'composite_rankings_{year}_week{week}.csv'\n",
        "final_rankings.to_csv(csv_path, index=False)\n",
        "\n",
        "# Save to root for backward compatibility\n",
        "final_rankings.to_csv('./final_rankings.csv', index=False)\n",
        "\n",
        "print('âœ… Final rankings exported:')\n",
        "print(f'   {csv_path}')\n",
        "print(f'   ./final_rankings.csv (for backward compatibility)')\n",
        "print(f'\\nðŸ“Š Total teams ranked: {len(final_rankings)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Diagnostic: Conference Distribution in Top 25\n",
        "\n",
        "top25 = composite_df.head(25)\n",
        "\n",
        "print('=' * 80)\n",
        "print('DIAGNOSTIC: Top 25 Conference Distribution')\n",
        "print('=' * 80)\n",
        "print()\n",
        "\n",
        "conf_counts = top25['conference'].value_counts()\n",
        "print('By Conference:')\n",
        "for conf, count in conf_counts.items():\n",
        "    tier = get_conference_tier(conf)\n",
        "    print(f'  {conf} ({tier}): {count} teams')\n",
        "\n",
        "print()\n",
        "tier_counts = top25['conf_tier'].value_counts()\n",
        "print('By Tier:')\n",
        "for tier, count in tier_counts.items():\n",
        "    print(f'  {tier}: {count} teams ({count/25*100:.1f}%)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization: Component Contributions\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Plot 1: Top 25 composite scores\n",
        "ax1 = axes[0, 0]\n",
        "top25 = final_rankings.head(25)\n",
        "colors = top25['conf_tier'].map({'P5': 'steelblue', 'G5': 'coral', 'IND': 'gray'})\n",
        "ax1.barh(range(25, 0, -1), top25['composite_score'], color=colors)\n",
        "ax1.set_yticks(range(25, 0, -1))\n",
        "ax1.set_yticklabels(top25['team'], fontsize=9)\n",
        "ax1.set_xlabel('Composite Score')\n",
        "ax1.set_title('Top 25 Teams by Composite Score (Color = Conference Tier)')\n",
        "ax1.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Add legend\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [\n",
        "    Patch(facecolor='steelblue', label='Power 5'),\n",
        "    Patch(facecolor='coral', label='Group of 5'),\n",
        "    Patch(facecolor='gray', label='Independent')\n",
        "]\n",
        "ax1.legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "# Plot 2: Component contributions for top 10\n",
        "ax2 = axes[0, 1]\n",
        "top10 = composite_df.head(10)\n",
        "x = np.arange(10)\n",
        "width = 0.2\n",
        "\n",
        "ax2.bar(x - 1.5*width, top10['resume_norm'] * weights['resume'], width, \n",
        "        label=f'Resume ({weights[\"resume\"]:.0%})', alpha=0.8)\n",
        "ax2.bar(x - 0.5*width, top10['predictive_norm'] * weights['predictive'], width, \n",
        "        label=f'Predictive ({weights[\"predictive\"]:.0%})', alpha=0.8)\n",
        "ax2.bar(x + 0.5*width, top10['sor_norm'] * weights['sor'], width, \n",
        "        label=f'SOR ({weights[\"sor\"]:.0%})', alpha=0.8)\n",
        "ax2.bar(x + 1.5*width, top10['sos_norm'] * weights['sos'], width, \n",
        "        label=f'SOS ({weights[\"sos\"]:.0%})', alpha=0.8)\n",
        "\n",
        "ax2.set_xlabel('Team')\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(top10['team'], rotation=45, ha='right', fontsize=9)\n",
        "ax2.set_ylabel('Weighted Contribution')\n",
        "ax2.set_title('Component Contributions to Top 10 Rankings')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Plot 3: Resume vs Predictive scatter\n",
        "ax3 = axes[1, 0]\n",
        "for tier, color, marker in [('P5', 'steelblue', 'o'), ('G5', 'coral', '^'), ('IND', 'gray', 's')]:\n",
        "    tier_teams = composite_df[composite_df['conf_tier'] == tier]\n",
        "    ax3.scatter(tier_teams['resume_score'], tier_teams['predictive_score'], \n",
        "               c=color, marker=marker, label=tier, alpha=0.6)\n",
        "\n",
        "for i, row in composite_df.head(12).iterrows():\n",
        "    ax3.annotate(row['team'], (row['resume_score'], row['predictive_score']), \n",
        "                fontsize=7, alpha=0.7)\n",
        "\n",
        "ax3.set_xlabel('Resume Score (What You\\'ve Done)')\n",
        "ax3.set_ylabel('Predictive Score (How Good You Are)')\n",
        "ax3.set_title('Resume vs Predictive Rankings')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: Conference tier distribution\n",
        "ax4 = axes[1, 1]\n",
        "tier_dist = []\n",
        "for cutoff in [12, 25, 50, len(composite_df)]:\n",
        "    top_n = composite_df.head(cutoff)\n",
        "    tier_dist.append({\n",
        "        'Top': f'Top {cutoff}',\n",
        "        'P5': (top_n['conf_tier'] == 'P5').sum(),\n",
        "        'G5': (top_n['conf_tier'] == 'G5').sum(),\n",
        "        'IND': (top_n['conf_tier'] == 'IND').sum()\n",
        "    })\n",
        "\n",
        "dist_df = pd.DataFrame(tier_dist)\n",
        "x_pos = np.arange(len(dist_df))\n",
        "width = 0.25\n",
        "\n",
        "ax4.bar(x_pos - width, dist_df['P5'], width, label='Power 5', color='steelblue')\n",
        "ax4.bar(x_pos, dist_df['G5'], width, label='Group of 5', color='coral')\n",
        "ax4.bar(x_pos + width, dist_df['IND'], width, label='Independent', color='gray')\n",
        "\n",
        "ax4.set_xlabel('Ranking Cutoff')\n",
        "ax4.set_ylabel('Number of Teams')\n",
        "ax4.set_title('Conference Tier Distribution by Ranking')\n",
        "ax4.set_xticks(x_pos)\n",
        "ax4.set_xticklabels(dist_df['Top'])\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "viz_path = viz_dir / f'composite_analysis_{year}_week{week}.png'\n",
        "plt.savefig(viz_path, dpi=150, bbox_inches='tight')\n",
        "print(f'\\nâœ… Visualization saved: {viz_path}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "Composite rankings complete with conference-aware adjustments.\n",
        "\n",
        "**Next Steps:**\n",
        "- `04_resume_analysis.ipynb` - Detailed team resume sheets\n",
        "- `05_playoff_selection.ipynb` - 12-team bracket selection\n",
        "- `08_validation_backtesting.ipynb` - Validate against historical CFP rankings"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
