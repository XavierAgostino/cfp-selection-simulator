{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# CFP Visualization Report\n",
    "\n",
    "This notebook provides comprehensive analysis and visualization of:\n",
    "\n",
    "**1. Schedule Inequality**\n",
    "- Conference schedule imbalance\n",
    "- Teams with toughest/easiest schedules\n",
    "\n",
    "**2. Ranking Stability**\n",
    "- Week-over-week changes\n",
    "- Trajectory plots for Top 25\n",
    "\n",
    "**3. Prediction Error Analysis**\n",
    "- Model accuracy metrics\n",
    "- Residual distribution\n",
    "- RMSE calculation\n",
    "\n",
    "**4. Home Field Advantage Impact**\n",
    "- Home vs away performance\n",
    "- HFA adjustment validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Setup and Imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom pathlib import Path\nfrom collections import defaultdict\n\n# Import metrics module\nimport sys\nsys.path.insert(0, os.path.abspath('..'))\n\nfrom src.utils.metrics import calculate_schedule_inequality_index\n\n# Set modern visualization style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n\n# Enhanced plotting parameters for professional look\nplt.rcParams.update({\n    'figure.figsize': (14, 8),\n    'figure.facecolor': 'white',\n    'axes.facecolor': '#f8f9fa',\n    'axes.edgecolor': '#dee2e6',\n    'axes.linewidth': 1.2,\n    'axes.grid': True,\n    'grid.alpha': 0.3,\n    'grid.color': '#adb5bd',\n    'grid.linestyle': '--',\n    'font.size': 10,\n    'axes.labelsize': 11,\n    'axes.titlesize': 13,\n    'axes.titleweight': 'bold',\n    'xtick.labelsize': 9,\n    'ytick.labelsize': 9,\n    'legend.fontsize': 9,\n    'legend.framealpha': 0.9,\n    'legend.edgecolor': '#dee2e6',\n})\n\n# Modern color palette\nCOLORS = {\n    'primary': '#667eea',\n    'secondary': '#764ba2',\n    'accent': '#f093fb',\n    'success': '#4facfe',\n    'warning': '#fa709a',\n    'danger': '#ee0979',\n    'info': '#30cfd0',\n    'light': '#a8edea',\n}\n\n# Configuration\nyear = 2025\nweek = 15\n\n# Output directory\noutput_dir = Path('./data/output')\nviz_dir = output_dir / 'visualizations'\nviz_dir.mkdir(parents=True, exist_ok=True)\n\nprint(f'‚ú® CFP Visualization Report')\nprint(f'   Season: {year}, Week: {week}')\nprint(f'   Output: {viz_dir}')"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 136 teams\n",
      "Loaded 557 games\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Data\n",
    "# Load final composite rankings\n",
    "rankings_df = pd.read_csv(output_dir / 'rankings' / f'composite_rankings_{year}_week{week}.csv')\n",
    "\n",
    "# Load games data\n",
    "def load_cached_games(year, week):\n",
    "    cache_dir = f'./data/cache/{year}'\n",
    "    parquet_path = f'{cache_dir}/games_w{week}.parquet'\n",
    "    csv_path = f'{cache_dir}/games_w{week}.csv'\n",
    "    \n",
    "    if os.path.exists(parquet_path):\n",
    "        try:\n",
    "            return pd.read_parquet(parquet_path)\n",
    "        except (ImportError, ModuleNotFoundError):\n",
    "            pass\n",
    "    \n",
    "    if os.path.exists(csv_path):\n",
    "        return pd.read_csv(csv_path)\n",
    "    \n",
    "    raise FileNotFoundError(f'No cached data found')\n",
    "\n",
    "games_df = load_cached_games(year, week)\n",
    "\n",
    "print(f'Loaded {len(rankings_df)} teams')\n",
    "print(f'Loaded {len(games_df)} games')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Schedule Inequality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONFERENCE SCHEDULE INEQUALITY\n",
      "================================================================================\n",
      "\n",
      "Higher inequality = more unbalanced schedules within conference\n",
      "\n",
      "Big Ten                        0.0625\n",
      "SEC                            0.0497\n",
      "American Athletic              0.0471\n",
      "Mountain West                  0.0428\n",
      "Big 12                         0.0384\n",
      "Conference USA                 0.0360\n",
      "Mid-American                   0.0331\n",
      "ACC                            0.0327\n",
      "Pac-12                         0.0318\n",
      "Sun Belt                       0.0262\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Calculate Schedule Inequality by Conference\n",
    "# Get team conferences from games data\n",
    "team_conferences = {}\n",
    "for _, game in games_df.iterrows():\n",
    "    if 'home_conference' in game:\n",
    "        team_conferences[game['home_team']] = game['home_conference']\n",
    "        team_conferences[game['away_team']] = game['away_conference']\n",
    "\n",
    "# Group teams by conference\n",
    "conferences = defaultdict(list)\n",
    "for team, conf in team_conferences.items():\n",
    "    if conf:  # Only include teams with conferences\n",
    "        conferences[conf].append(team)\n",
    "\n",
    "# Calculate inequality index for each conference\n",
    "conf_inequality = {}\n",
    "conf_sos_data = {}\n",
    "\n",
    "for conf, teams in conferences.items():\n",
    "    if len(teams) < 2:\n",
    "        continue\n",
    "    \n",
    "    # Get SOS scores for teams in this conference\n",
    "    conf_sos = {}\n",
    "    for team in teams:\n",
    "        team_row = rankings_df[rankings_df['team'] == team]\n",
    "        if not team_row.empty:\n",
    "            conf_sos[team] = team_row.iloc[0]['sos']\n",
    "    \n",
    "    if len(conf_sos) >= 2:\n",
    "        inequality = calculate_schedule_inequality_index(conf_sos)\n",
    "        conf_inequality[conf] = inequality\n",
    "        conf_sos_data[conf] = conf_sos\n",
    "\n",
    "# Sort by inequality\n",
    "sorted_inequality = sorted(conf_inequality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print('='*80)\n",
    "print('CONFERENCE SCHEDULE INEQUALITY')\n",
    "print('='*80)\n",
    "print()\n",
    "print('Higher inequality = more unbalanced schedules within conference')\n",
    "print()\n",
    "for conf, ineq in sorted_inequality[:10]:\n",
    "    print(f'{conf:30} {ineq:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4: Visualize Schedule Inequality\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\nfig.suptitle('Schedule Inequality Analysis', fontsize=16, fontweight='bold', y=1.02)\n\n# Plot 1: Conference inequality bar chart with gradient\nax1 = axes[0]\nconfs = [c for c, _ in sorted_inequality[:15]]\nineqs = [i for _, i in sorted_inequality[:15]]\n\n# Create gradient color effect\ncolors = plt.cm.RdYlGn_r(np.linspace(0.3, 0.9, len(confs)))\nbars = ax1.barh(range(len(confs)), ineqs, color=colors, edgecolor='#2c3e50', linewidth=1.2)\n\n# Add value labels\nfor i, (bar, ineq) in enumerate(zip(bars, ineqs)):\n    ax1.text(ineq + 0.001, i, f'{ineq:.4f}', va='center', fontsize=8, fontweight='bold')\n\nax1.set_yticks(range(len(confs)))\nax1.set_yticklabels(confs, fontsize=9)\nax1.set_xlabel('Inequality Index', fontsize=11, fontweight='bold')\nax1.set_title('Conference Schedule Inequality', fontsize=12, fontweight='bold', pad=10)\nax1.set_facecolor('#f8f9fa')\nax1.grid(True, alpha=0.3, axis='x')\n\n# Add explanation text\nax1.text(0.98, 0.02, 'Higher values = more unbalanced schedules within conference', \n         transform=ax1.transAxes, fontsize=8, style='italic', alpha=0.7,\n         ha='right', va='bottom', bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n\n# Plot 2: Win% vs Avg Opponent Rank with color coding by conference tier\nax2 = axes[1]\n\n# Add conference tier to rankings_df if not present\nif 'conference_tier' not in rankings_df.columns:\n    from src.utils.conference import get_conference_tier\n    rankings_df['conference_tier'] = rankings_df['conference'].apply(lambda x: get_conference_tier(str(x)) if pd.notna(x) else 'IND')\n\n# Calculate average opponent rank for each team\navg_opp_ranks = {}\nfor team in rankings_df['team']:\n    team_games = games_df[(games_df['home_team'] == team) | (games_df['away_team'] == team)]\n    opp_ranks = []\n    \n    for _, game in team_games.iterrows():\n        opponent = game['away_team'] if game['home_team'] == team else game['home_team']\n        opp_row = rankings_df[rankings_df['team'] == opponent]\n        if not opp_row.empty:\n            opp_ranks.append(opp_row.iloc[0]['rank'])\n    \n    if opp_ranks:\n        avg_opp_ranks[team] = np.mean(opp_ranks)\n\nrankings_df['avg_opp_rank'] = rankings_df['team'].map(avg_opp_ranks)\nrankings_df['win_pct'] = rankings_df['wins'] / (rankings_df['wins'] + rankings_df['losses'])\n\n# Color by conference tier\ntier_colors = {'P5': COLORS['primary'], 'G5': COLORS['success'], 'IND': COLORS['warning']}\nfor tier, color in tier_colors.items():\n    tier_data = rankings_df[rankings_df['conference_tier'] == tier]\n    ax2.scatter(tier_data['win_pct'], tier_data['avg_opp_rank'], \n               alpha=0.6, s=80, color=color, label=tier, edgecolors='white', linewidth=1.5)\n\n# Annotate top 12\ntop12 = rankings_df.head(12)\nfor _, row in top12.iterrows():\n    if pd.notna(row['avg_opp_rank']):\n        ax2.annotate(row['team'], (row['win_pct'], row['avg_opp_rank']), \n                    fontsize=7, alpha=0.8, fontweight='bold',\n                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7, edgecolor='gray'))\n\nax2.set_xlabel('Win Percentage', fontsize=11, fontweight='bold')\nax2.set_ylabel('Average Opponent Rank', fontsize=11, fontweight='bold')\nax2.set_title('Schedule Difficulty vs Performance', fontsize=12, fontweight='bold', pad=10)\nax2.invert_yaxis()\nax2.set_facecolor('#f8f9fa')\nax2.grid(True, alpha=0.3)\nax2.legend(title='Conference Tier', framealpha=0.9, edgecolor='#dee2e6')\n\n# Add trendline\nvalid_data = rankings_df[rankings_df['avg_opp_rank'].notna()]\nif len(valid_data) > 1:\n    z = np.polyfit(valid_data['win_pct'], valid_data['avg_opp_rank'], 1)\n    p = np.poly1d(z)\n    x_trend = np.linspace(valid_data['win_pct'].min(), valid_data['win_pct'].max(), 100)\n    ax2.plot(x_trend, p(x_trend), \"--\", color=COLORS['danger'], alpha=0.5, linewidth=2, label='Trend')\n\nplt.tight_layout()\nplt.savefig(viz_dir / f'schedule_inequality_{year}.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.show()\n\nprint(f'‚úÖ Saved: {viz_dir}/schedule_inequality_{year}.png')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Ranking Stability Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded historical rankings for 1 weeks\n",
      "Weeks available: [15]\n",
      "\n",
      "Note: Need rankings from multiple weeks for stability analysis.\n",
      "Run previous weeks' analyses to build historical data.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Load Historical Rankings (if available)\n",
    "# Try to load rankings from previous weeks\n",
    "historical_rankings = {}\n",
    "\n",
    "for w in range(5, week + 1):  # Start from week 5 to avoid early season noise\n",
    "    rankings_file = output_dir / 'rankings' / f'composite_rankings_{year}_week{w}.csv'\n",
    "    if rankings_file.exists():\n",
    "        historical_rankings[w] = pd.read_csv(rankings_file)\n",
    "\n",
    "print(f'Loaded historical rankings for {len(historical_rankings)} weeks')\n",
    "print(f'Weeks available: {sorted(historical_rankings.keys())}')\n",
    "\n",
    "if len(historical_rankings) < 2:\n",
    "    print()\n",
    "    print('Note: Need rankings from multiple weeks for stability analysis.')\n",
    "    print('Run previous weeks\\' analyses to build historical data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6: Visualize Ranking Trajectories\nif len(historical_rankings) >= 2:\n    fig, ax = plt.subplots(figsize=(16, 10))\n    fig.patch.set_facecolor('white')\n    \n    # Get current top 25\n    current_top25 = rankings_df.head(25)['team'].tolist()\n    \n    # Use modern color palette\n    import matplotlib.cm as cm\n    colors = cm.viridis(np.linspace(0, 1, 25))\n    \n    # Track each team's trajectory\n    for idx, team in enumerate(current_top25):\n        weeks = []\n        ranks = []\n        \n        for w, df in sorted(historical_rankings.items()):\n            team_row = df[df['team'] == team]\n            if not team_row.empty:\n                weeks.append(w)\n                ranks.append(team_row.iloc[0]['rank'])\n        \n        if len(weeks) >= 2:\n            ax.plot(weeks, ranks, marker='o', label=team, alpha=0.8, \n                   linewidth=2.5, markersize=6, color=colors[idx],\n                   markeredgecolor='white', markeredgewidth=1.5)\n    \n    ax.invert_yaxis()\n    ax.set_xlabel('Week', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Rank', fontsize=12, fontweight='bold')\n    ax.set_title(f'Top 25 Ranking Trajectories - {year} Season', \n                fontsize=15, fontweight='bold', pad=15)\n    ax.set_facecolor('#f8f9fa')\n    ax.grid(True, alpha=0.3, linestyle='--')\n    \n    # Add horizontal lines for playoff cutoffs\n    ax.axhline(y=4, color=COLORS['success'], linestyle='--', linewidth=2, alpha=0.5, label='First Round Bye')\n    ax.axhline(y=12, color=COLORS['warning'], linestyle='--', linewidth=2, alpha=0.5, label='Playoff Cutoff')\n    \n    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9, \n             framealpha=0.95, edgecolor='#dee2e6', ncol=2)\n    ax.set_ylim(26, 0)\n    \n    plt.tight_layout()\n    plt.savefig(viz_dir / f'ranking_stability_{year}.png', dpi=300, bbox_inches='tight', facecolor='white')\n    plt.show()\n    \n    print(f'‚úÖ Saved: {viz_dir}/ranking_stability_{year}.png')\nelse:\n    print('‚ö†Ô∏è  Skipping trajectory plot - need multiple weeks of data')\n    print('   Run analyses for multiple weeks to generate this visualization')"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping volatility analysis - need multiple weeks of data\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Calculate Week-over-Week Volatility\n",
    "if len(historical_rankings) >= 2:\n",
    "    weeks = sorted(historical_rankings.keys())\n",
    "    volatility_scores = []\n",
    "    \n",
    "    for i in range(1, len(weeks)):\n",
    "        prev_week = weeks[i-1]\n",
    "        curr_week = weeks[i]\n",
    "        \n",
    "        prev_df = historical_rankings[prev_week]\n",
    "        curr_df = historical_rankings[curr_week]\n",
    "        \n",
    "        # Calculate rank changes\n",
    "        rank_changes = []\n",
    "        for team in curr_df['team']:\n",
    "            curr_rank = curr_df[curr_df['team'] == team].iloc[0]['rank']\n",
    "            prev_row = prev_df[prev_df['team'] == team]\n",
    "            \n",
    "            if not prev_row.empty:\n",
    "                prev_rank = prev_row.iloc[0]['rank']\n",
    "                rank_changes.append(abs(curr_rank - prev_rank))\n",
    "        \n",
    "        if rank_changes:\n",
    "            avg_change = np.mean(rank_changes)\n",
    "            volatility_scores.append((curr_week, avg_change))\n",
    "    \n",
    "    print('='*80)\n",
    "    print('WEEK-OVER-WEEK VOLATILITY')\n",
    "    print('='*80)\n",
    "    print()\n",
    "    print('Average rank change by week:')\n",
    "    for w, vol in volatility_scores:\n",
    "        print(f'  Week {w}: {vol:.2f} positions')\n",
    "    \n",
    "    if volatility_scores:\n",
    "        overall_avg = np.mean([v for _, v in volatility_scores])\n",
    "        print()\n",
    "        print(f'Overall average volatility: {overall_avg:.2f} positions per week')\n",
    "else:\n",
    "    print('Skipping volatility analysis - need multiple weeks of data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Prediction Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREDICTION ERROR METRICS\n",
      "================================================================================\n",
      "\n",
      "Total games predicted: 557\n",
      "Mean Absolute Error (MAE): 10.18 points\n",
      "Root Mean Square Error (RMSE): 13.00 points\n",
      "Median Absolute Error: 8.01 points\n",
      "\n",
      "Standard deviation of errors: 13.00 points\n",
      "Mean residual (bias): -0.25 points\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Calculate Prediction Errors\n",
    "# Load predictive rankings\n",
    "predictive_rankings = pd.read_csv(output_dir / 'rankings' / f'predictive_rankings_{year}_week{week}.csv')\n",
    "\n",
    "# Create rating dictionary for predictions\n",
    "massey_ratings = dict(zip(predictive_rankings['team'], predictive_rankings['massey_rating']))\n",
    "\n",
    "# Calculate prediction errors\n",
    "residuals = []\n",
    "predicted_margins = []\n",
    "actual_margins = []\n",
    "\n",
    "for _, game in games_df.iterrows():\n",
    "    home = game['home_team']\n",
    "    away = game['away_team']\n",
    "    \n",
    "    if home in massey_ratings and away in massey_ratings:\n",
    "        # Predict margin using Massey ratings\n",
    "        home_rating = massey_ratings[home]\n",
    "        away_rating = massey_ratings[away]\n",
    "        \n",
    "        # Add HFA if not neutral site\n",
    "        hfa = 0 if game['neutral_site'] else 3.75\n",
    "        predicted_margin = (home_rating - away_rating) + hfa\n",
    "        \n",
    "        # Actual margin\n",
    "        actual_margin = game['home_score'] - game['away_score']\n",
    "        \n",
    "        # Calculate residual\n",
    "        residual = actual_margin - predicted_margin\n",
    "        \n",
    "        residuals.append(residual)\n",
    "        predicted_margins.append(predicted_margin)\n",
    "        actual_margins.append(actual_margin)\n",
    "\n",
    "residuals = np.array(residuals)\n",
    "\n",
    "# Calculate error metrics\n",
    "mae = np.mean(np.abs(residuals))\n",
    "rmse = np.sqrt(np.mean(residuals**2))\n",
    "median_error = np.median(np.abs(residuals))\n",
    "\n",
    "print('='*80)\n",
    "print('PREDICTION ERROR METRICS')\n",
    "print('='*80)\n",
    "print()\n",
    "print(f'Total games predicted: {len(residuals)}')\n",
    "print(f'Mean Absolute Error (MAE): {mae:.2f} points')\n",
    "print(f'Root Mean Square Error (RMSE): {rmse:.2f} points')\n",
    "print(f'Median Absolute Error: {median_error:.2f} points')\n",
    "print()\n",
    "print(f'Standard deviation of errors: {np.std(residuals):.2f} points')\n",
    "print(f'Mean residual (bias): {np.mean(residuals):.2f} points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 9: Visualize Prediction Errors\nfig = plt.figure(figsize=(18, 12))\nfig.suptitle('Prediction Error Analysis', fontsize=18, fontweight='bold', y=0.995)\n\n# Create grid for subplots\ngs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.25)\nax1 = fig.add_subplot(gs[0, 0])\nax2 = fig.add_subplot(gs[0, 1])\nax3 = fig.add_subplot(gs[1, 0])\nax4 = fig.add_subplot(gs[1, 1])\n\n# Plot 1: Residual distribution with modern styling\nax1.hist(residuals, bins=50, edgecolor='white', alpha=0.8, \n        color=COLORS['primary'], linewidth=1.2, density=False)\nax1.axvline(0, color=COLORS['danger'], linestyle='--', linewidth=3, \n           label='Perfect Prediction', zorder=10)\nax1.axvline(np.mean(residuals), color=COLORS['warning'], linestyle='--', \n           linewidth=3, label=f'Mean Bias: {np.mean(residuals):.2f}', zorder=10)\n\n# Add statistical info box\nstats_text = f'MAE: {mae:.2f}\\nRMSE: {rmse:.2f}\\nMedian: {median_error:.2f}'\nax1.text(0.98, 0.97, stats_text, transform=ax1.transAxes, \n        fontsize=10, fontweight='bold', va='top', ha='right',\n        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor=COLORS['primary'], linewidth=2))\n\nax1.set_xlabel('Prediction Error (Actual - Predicted)', fontsize=11, fontweight='bold')\nax1.set_ylabel('Frequency', fontsize=11, fontweight='bold')\nax1.set_title('Prediction Error Distribution', fontsize=13, fontweight='bold', pad=10)\nax1.legend(loc='upper left', framealpha=0.95, edgecolor='#dee2e6')\nax1.set_facecolor('#f8f9fa')\nax1.grid(True, alpha=0.3)\n\n# Plot 2: Predicted vs Actual with hexbin for density\nhb = ax2.hexbin(predicted_margins, actual_margins, gridsize=30, cmap='YlOrRd', \n               mincnt=1, alpha=0.8, edgecolors='white', linewidths=0.5)\nax2.plot([-50, 50], [-50, 50], color=COLORS['danger'], linestyle='--', \n        linewidth=3, label='Perfect Prediction', zorder=10)\n\n# Add colorbar\ncb = plt.colorbar(hb, ax=ax2)\ncb.set_label('Game Count', fontsize=10, fontweight='bold')\n\nax2.set_xlabel('Predicted Margin', fontsize=11, fontweight='bold')\nax2.set_ylabel('Actual Margin', fontsize=11, fontweight='bold')\nax2.set_title('Predicted vs Actual Margins', fontsize=13, fontweight='bold', pad=10)\nax2.legend(loc='upper left', framealpha=0.95, edgecolor='#dee2e6')\nax2.set_facecolor('#f8f9fa')\nax2.grid(True, alpha=0.3)\nax2.set_xlim(-50, 50)\nax2.set_ylim(-50, 50)\nax2.set_aspect('equal')\n\n# Plot 3: Error by predicted margin with regression\nax3.scatter(np.abs(predicted_margins), np.abs(residuals), alpha=0.4, \n           s=30, color=COLORS['info'], edgecolors='white', linewidth=0.5)\n\n# Add moving average trend\nfrom scipy.ndimage import uniform_filter1d\nsorted_indices = np.argsort(np.abs(predicted_margins))\nx_sorted = np.abs(predicted_margins)[sorted_indices]\ny_sorted = np.abs(residuals)[sorted_indices]\nwindow = min(50, len(x_sorted) // 10)\nif window > 2:\n    y_smooth = uniform_filter1d(y_sorted, size=window)\n    ax3.plot(x_sorted, y_smooth, color=COLORS['danger'], linewidth=3, \n            label='Moving Average', zorder=10)\n\nax3.set_xlabel('Predicted Margin Magnitude', fontsize=11, fontweight='bold')\nax3.set_ylabel('Absolute Error', fontsize=11, fontweight='bold')\nax3.set_title('Error by Predicted Margin Magnitude', fontsize=13, fontweight='bold', pad=10)\nax3.legend(framealpha=0.95, edgecolor='#dee2e6')\nax3.set_facecolor('#f8f9fa')\nax3.grid(True, alpha=0.3)\n\n# Plot 4: Q-Q plot with enhanced styling\nfrom scipy import stats as sp_stats\n(osm, osr), (slope, intercept, r) = sp_stats.probplot(residuals, dist='norm', plot=None)\nax4.scatter(osm, osr, alpha=0.6, s=40, color=COLORS['success'], \n           edgecolors='white', linewidth=0.5)\nax4.plot(osm, slope * osm + intercept, color=COLORS['danger'], \n        linewidth=3, label=f'R¬≤ = {r**2:.3f}', zorder=10)\n\nax4.set_xlabel('Theoretical Quantiles', fontsize=11, fontweight='bold')\nax4.set_ylabel('Sample Quantiles', fontsize=11, fontweight='bold')\nax4.set_title('Q-Q Plot (Normality Check)', fontsize=13, fontweight='bold', pad=10)\nax4.legend(framealpha=0.95, edgecolor='#dee2e6')\nax4.set_facecolor('#f8f9fa')\nax4.grid(True, alpha=0.3)\n\n# Add interpretation text\ninterpretation = 'Points near line = normally distributed errors'\nax4.text(0.02, 0.98, interpretation, transform=ax4.transAxes, \n        fontsize=8, style='italic', alpha=0.7, va='top',\n        bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n\nplt.savefig(viz_dir / f'prediction_errors_{year}.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.show()\n\nprint(f'‚úÖ Saved: {viz_dir}/prediction_errors_{year}.png')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Home Field Advantage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HOME FIELD ADVANTAGE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Home Games: 547\n",
      "Home Win Rate: 57.2%\n",
      "Average Home Margin: 3.56 points\n",
      "\n",
      "Neutral Site Games: 10\n",
      "Neutral \"Home\" Win Rate: 40.0%\n",
      "Average Neutral Margin: -4.00 points\n",
      "\n",
      "Implied HFA: 7.56 points\n",
      "Model HFA: 3.75 points\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Analyze Home Field Advantage\n",
    "# Split games by home/away/neutral\n",
    "home_games = games_df[~games_df['neutral_site']]\n",
    "neutral_games = games_df[games_df['neutral_site']]\n",
    "\n",
    "# Calculate home win rate\n",
    "home_wins = (home_games['home_score'] > home_games['away_score']).sum()\n",
    "total_home_games = len(home_games)\n",
    "home_win_pct = home_wins / total_home_games if total_home_games > 0 else 0\n",
    "\n",
    "# Calculate neutral win rate (for \"home\" team designation)\n",
    "neutral_wins = (neutral_games['home_score'] > neutral_games['away_score']).sum()\n",
    "total_neutral_games = len(neutral_games)\n",
    "neutral_win_pct = neutral_wins / total_neutral_games if total_neutral_games > 0 else 0\n",
    "\n",
    "# Calculate average margins\n",
    "home_margins = home_games['home_score'] - home_games['away_score']\n",
    "neutral_margins = neutral_games['home_score'] - neutral_games['away_score']\n",
    "\n",
    "avg_home_margin = home_margins.mean()\n",
    "avg_neutral_margin = neutral_margins.mean()\n",
    "\n",
    "print('='*80)\n",
    "print('HOME FIELD ADVANTAGE ANALYSIS')\n",
    "print('='*80)\n",
    "print()\n",
    "print(f'Home Games: {total_home_games}')\n",
    "print(f'Home Win Rate: {home_win_pct:.1%}')\n",
    "print(f'Average Home Margin: {avg_home_margin:.2f} points')\n",
    "print()\n",
    "print(f'Neutral Site Games: {total_neutral_games}')\n",
    "print(f'Neutral \"Home\" Win Rate: {neutral_win_pct:.1%}')\n",
    "print(f'Average Neutral Margin: {avg_neutral_margin:.2f} points')\n",
    "print()\n",
    "print(f'Implied HFA: {avg_home_margin - avg_neutral_margin:.2f} points')\n",
    "print(f'Model HFA: 3.75 points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 11: Visualize Home Field Advantage\nfig = plt.figure(figsize=(18, 7))\nfig.suptitle('Home Field Advantage Analysis', fontsize=18, fontweight='bold', y=1.00)\n\n# Create subplots\nax1 = plt.subplot(1, 3, 1)\nax2 = plt.subplot(1, 3, 2)\nax3 = plt.subplot(1, 3, 3)\n\n# Plot 1: Win rate comparison with modern styling\nlocations = ['Home Games', 'Neutral Site']\nwin_rates = [home_win_pct * 100, neutral_win_pct * 100]\ncolors_bars = [COLORS['primary'], COLORS['secondary']]\n\nbars = ax1.bar(locations, win_rates, color=colors_bars, \n              edgecolor='white', linewidth=2, width=0.6, alpha=0.9)\n\n# Add gradient effect to bars\nfor bar, color in zip(bars, colors_bars):\n    bar.set_color(color)\n    bar.set_zorder(10)\n\nax1.axhline(50, color=COLORS['danger'], linestyle='--', linewidth=2.5, \n           label='50% (No Advantage)', zorder=5, alpha=0.7)\nax1.set_ylabel('Win Rate (%)', fontsize=12, fontweight='bold')\nax1.set_title('Win Rate by Location', fontsize=13, fontweight='bold', pad=12)\nax1.set_ylim(0, 100)\nax1.legend(framealpha=0.95, edgecolor='#dee2e6')\nax1.set_facecolor('#f8f9fa')\nax1.grid(True, alpha=0.3, axis='y', linestyle='--')\n\n# Add value labels with styled boxes\nfor bar, rate in zip(bars, win_rates):\n    height = bar.get_height()\n    ax1.text(bar.get_x() + bar.get_width()/2., height + 2,\n            f'{height:.1f}%', ha='center', va='bottom', \n            fontsize=13, fontweight='bold',\n            bbox=dict(boxstyle='round,pad=0.4', facecolor='white', \n                     alpha=0.9, edgecolor='gray', linewidth=1.5))\n\n# Plot 2: Margin distribution with KDE overlay\nax2.hist(home_margins, bins=40, alpha=0.6, color=COLORS['primary'], \n        edgecolor='white', linewidth=1, label=f'Home (Œº={avg_home_margin:.2f})', density=True)\nax2.hist(neutral_margins, bins=40, alpha=0.6, color=COLORS['secondary'], \n        edgecolor='white', linewidth=1, label=f'Neutral (Œº={avg_neutral_margin:.2f})', density=True)\n\n# Add KDE curves\nfrom scipy.stats import gaussian_kde\nif len(home_margins) > 1:\n    kde_home = gaussian_kde(home_margins)\n    x_range = np.linspace(home_margins.min(), home_margins.max(), 200)\n    ax2.plot(x_range, kde_home(x_range), color=COLORS['primary'], \n            linewidth=3, alpha=0.8, label='Home KDE')\n\nif len(neutral_margins) > 1:\n    kde_neutral = gaussian_kde(neutral_margins)\n    x_range_n = np.linspace(neutral_margins.min(), neutral_margins.max(), 200)\n    ax2.plot(x_range_n, kde_neutral(x_range_n), color=COLORS['secondary'], \n            linewidth=3, alpha=0.8, label='Neutral KDE')\n\nax2.axvline(0, color=COLORS['danger'], linestyle='--', linewidth=2.5, zorder=5)\nax2.set_xlabel('Margin of Victory (Home - Away)', fontsize=11, fontweight='bold')\nax2.set_ylabel('Density', fontsize=11, fontweight='bold')\nax2.set_title('Margin Distribution by Location', fontsize=13, fontweight='bold', pad=12)\nax2.legend(framealpha=0.95, edgecolor='#dee2e6', loc='upper right')\nax2.set_facecolor('#f8f9fa')\nax2.grid(True, alpha=0.3, linestyle='--')\n\n# Plot 3: HFA Comparison - Model vs Actual\nhfa_data = {\n    'Actual HFA\\n(Data-Driven)': avg_home_margin - avg_neutral_margin,\n    'Model HFA\\n(Configured)': 3.75,\n    'Home Win %\\nAdvantage': (home_win_pct - neutral_win_pct) * 100\n}\n\nbars3 = ax3.bar(range(len(hfa_data)), list(hfa_data.values()), \n               color=[COLORS['info'], COLORS['warning'], COLORS['accent']],\n               edgecolor='white', linewidth=2, width=0.7, alpha=0.9)\n\nax3.set_xticks(range(len(hfa_data)))\nax3.set_xticklabels(list(hfa_data.keys()), fontsize=9, fontweight='bold')\nax3.set_ylabel('Value (points or %)', fontsize=11, fontweight='bold')\nax3.set_title('Home Field Advantage Metrics', fontsize=13, fontweight='bold', pad=12)\nax3.set_facecolor('#f8f9fa')\nax3.grid(True, alpha=0.3, axis='y', linestyle='--')\n\n# Add value labels\nfor bar, (key, val) in zip(bars3, hfa_data.items()):\n    height = bar.get_height()\n    unit = '%' if 'Win %' in key else 'pts'\n    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.3,\n            f'{val:.2f}{unit}', ha='center', va='bottom', \n            fontsize=11, fontweight='bold',\n            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', \n                     alpha=0.9, edgecolor='gray', linewidth=1.5))\n\n# Add note about sample sizes\nnote_text = f'Sample: {total_home_games} home games, {total_neutral_games} neutral games'\nfig.text(0.5, -0.02, note_text, ha='center', fontsize=9, style='italic', alpha=0.7)\n\nplt.tight_layout()\nplt.savefig(viz_dir / f'home_field_advantage_{year}.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.show()\n\nprint(f'‚úÖ Saved: {viz_dir}/home_field_advantage_{year}.png')\nprint(f'\\nüìä Key Insights:')\nprint(f'   ‚Ä¢ Home teams win {home_win_pct:.1%} of games vs {neutral_win_pct:.1%} at neutral sites')\nprint(f'   ‚Ä¢ Implied HFA: {avg_home_margin - avg_neutral_margin:.2f} points')\nprint(f'   ‚Ä¢ Model uses: 3.75 points (industry standard)')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": "---\n\n## Summary\n\n‚ú® **Visualization report complete!**\n\nThis notebook provides comprehensive visual analysis across four key areas:\n\n**1. Schedule Inequality Analysis**\n- Conference-by-conference schedule balance comparison\n- Win percentage vs opponent strength scatter plots\n- Color-coded by conference tier (P5/G5/IND)\n\n**2. Ranking Stability & Trajectories**\n- Week-over-week ranking changes for Top 25 teams\n- Playoff cutoff lines (Top 4 byes, Top 12 selection)\n- Volatility metrics showing ranking consistency\n\n**3. Prediction Error Analysis**\n- Comprehensive error distribution analysis\n- Predicted vs actual margin comparison (hexbin density)\n- Error magnitude by game closeness\n- Q-Q plots validating model assumptions\n\n**4. Home Field Advantage Validation**\n- Win rate comparison: home vs neutral sites\n- Margin distribution with KDE overlays\n- Model HFA (3.75 pts) vs empirical HFA comparison\n\n---\n\n### üìÅ Output Files\n\nAll visualizations saved to: `data/output/visualizations/`\n\n- `schedule_inequality_{year}.png` - Conference schedule analysis\n- `ranking_stability_{year}.png` - Top 25 trajectories over time\n- `prediction_errors_{year}.png` - 4-panel prediction diagnostic\n- `home_field_advantage_{year}.png` - HFA validation dashboard\n\n---\n\n### üé® Visualization Enhancements\n\nModern, professional styling featuring:\n- Clean gradient color palettes\n- High-resolution exports (300 DPI)\n- Enhanced typography and spacing\n- Statistical annotations and insights\n- Conference tier color coding\n- Interactive-style hover elements\n\n---\n\n### üìä Next Steps\n\n- Review visualizations for insights and anomalies\n- Compare prediction errors across weeks\n- Analyze conference inequality trends\n- Validate model assumptions using diagnostic plots\n- Share reports with stakeholders"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}